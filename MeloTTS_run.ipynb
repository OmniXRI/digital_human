{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cbf4f49-5e34-4857-9a30-6b62da264d66",
   "metadata": {},
   "source": [
    "# MeloTTS for OpenVINO 單獨運行含Gradio界面範例 (MeloTTS_run.ipynb)\n",
    "by Jack OmniXRI, 2024/12/12\n",
    "\n",
    "本範例為簡化版，運行前必需安裝好 OpenVINO 2024.4 Notebooks 虛擬環境並啟動。完整步驟可參考下列連結。  \n",
    "https://github.com/zhaohb/MeloTTS-OV/tree/speech-enhancement-and-npu  \n",
    "\n",
    "接著安裝 MeloTTS-OV (speech-enhancement-and-npu版本）  \n",
    "* 首先到 https://github.com/zhaohb/MeloTTS-OV/tree/speech-enhancement-and-npu  \n",
    "* 按下綠色「<> Code」，選擇「Download ZIP」，解壓縮後把 \\MeloTTS-OV-speech-enhancement-and-npu 複製到  \n",
    "OpenVINO Notebooks 路徑 \\openvino_notebooks\\notebooks\\ 下。(請不要直接使用 git clone 命令，這樣會誤下載到標準版本)  \n",
    "* 接著進到指定路徑，開始安裝必要套件。  \n",
    "cd speech-enhancement-and-npu  \n",
    "pip install -r requirements.txt  \n",
    "pip install openvino nncf  \n",
    "python setup.py develop # or  pip install -e .  \n",
    "python -m unidic download  \n",
    "python -m nltk.downloader averaged_perceptron_tagger_eng  \n",
    "pip install deepfilternet # optional for enhancing speech  \n",
    "pip install ffmpeg # 一定要裝，不然影音內容無法顯示  \n",
    "\n",
    "執行測試程式，會順便下載模型並轉換好，存放在 \\tts_ov_ZH 下，第一次執行要花較多時間下載及轉換模型。運行完會產生聲音檔案 ov_en_int8_ZH.wav ，可點擊播放測試。  \n",
    "python  test_tts.py --language ZH --tts_device CPU --bert_device CPU  \n",
    "\n",
    "完成上述步驟後才能運行下列簡易版程式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62b83161-58ea-4598-acf1-4910865f61fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\omnixri\\py310_openvino_env\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:nncf:NNCF initialized successfully. Supported frameworks detected: torch, tensorflow, onnx, openvino\n"
     ]
    }
   ],
   "source": [
    "from melo.api import TTS\n",
    "from pathlib import Path\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e0388c-9655-4f2a-a5cd-14881c4da40f",
   "metadata": {},
   "source": [
    "## MeloTTS 文字轉語音基本參數設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbaa8249-fa12-4c76-9e41-b800c54e0cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\omnixri\\py310_openvino_env\\lib\\site-packages\\df\\io.py:9: UserWarning: `torchaudio.backend.common.AudioMetaData` has been moved to `torchaudio.AudioMetaData`. Please update the import path.\n",
      "  from torchaudio.backend.common import AudioMetaData\n",
      "C:\\Users\\omnixri\\py310_openvino_env\\lib\\site-packages\\torch\\nn\\utils\\weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init tts_ov_ZH\\bert_int8_ZH.xml\n",
      "ov_path : tts_ov_ZH\\tts_int8_ZH.xml\n",
      " > Text split to sentences.\n",
      "我們討如何在 Intel 平台上轉換和優化 artificial intelligence 模型\n",
      " > ===========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                    | 0/1 [00:00<?, ?it/s]Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\omnixri\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.953 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use speech enhance\n",
      "\u001b[32m2024-12-12 18:51:36\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mRunning on torch 2.1.0+cpu\u001b[0m\n",
      "\u001b[32m2024-12-12 18:51:36\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mRunning on host omnixri\u001b[0m\n",
      "\u001b[32m2024-12-12 18:51:36\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mLoading model settings of DeepFilterNet3\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-12-12 18:51:36\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mUsing DeepFilterNet3 model at C:\\Users\\omnixri\\AppData\\Local\\DeepFilterNet\\DeepFilterNet\\Cache\\DeepFilterNet3\u001b[0m\n",
      "\u001b[32m2024-12-12 18:51:36\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mInitializing model `deepfilternet3`\u001b[0m\n",
      "\u001b[32m2024-12-12 18:51:36\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mFound checkpoint C:\\Users\\omnixri\\AppData\\Local\\DeepFilterNet\\DeepFilterNet\\Cache\\DeepFilterNet3\\checkpoints\\model_120.ckpt.best with epoch 120\u001b[0m\n",
      "\u001b[32m2024-12-12 18:51:36\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mRunning on device cpu\u001b[0m\n",
      "\u001b[32m2024-12-12 18:51:36\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mModel loaded\u001b[0m\n",
      "MeloTTS 文字轉語音共花費: 2828.01 ms\n"
     ]
    }
   ],
   "source": [
    "speed = 1.0 # 調整語速\n",
    "use_ov = True  # True 使用 OpenVINO, False 使用 PyTorch\n",
    "use_int8 = True # True 啟用 INT8 格式\n",
    "speech_enhance = True # True 啟用語音增強模式\n",
    "\n",
    "tts_device = \"CPU\" # 指定 TTS 推論裝置 , \"CPU\" 或 \"GPU\"（這裡指 Intel GPU）\n",
    "bert_device = \"CPU\" # 指定 Bert 推論裝置, \"CPU\" 或 \"GPU\" 或 \"NPU\"\n",
    "lang =  \"ZH\" # 設定語系, EN 英文, ZH 中文(含混合英文、簡繁中文皆可)\n",
    "\n",
    "# 指定測試文字轉語音字串\n",
    "if lang == \"ZH\":\n",
    "    text = \"我們討如何在 Intel 平台上轉換和優化 artificial intelligence 模型\"\n",
    "elif lang == \"EN\":\n",
    "    text = \"For Intel platforms, we explore the methods for converting and optimizing models.\"\n",
    "\n",
    "# 若指定語音增強模式則新增 process_audio() 函式\n",
    "if speech_enhance:\n",
    "    from df.enhance import enhance, init_df, load_audio, save_audio\n",
    "    import torchaudio\n",
    "\n",
    "    # 將輸入聲音檔案處理後轉存到新檔案中\n",
    "    def process_audio(input_file: str, output_file: str, new_sample_rate: int = 48000):\n",
    "        \"\"\"\n",
    "        Load an audio file, enhance it using a DeepFilterNet, and save the result.\n",
    "\n",
    "        Parameters:\n",
    "        input_file (str): Path to the input audio file.\n",
    "        output_file (str): Path to save the enhanced audio file.\n",
    "        new_sample_rate (int): Desired sample rate for the output audio file (default is 48000 Hz).\n",
    "        \"\"\"\n",
    "\n",
    "        model, df_state, _ = init_df()\n",
    "        audio, sr = torchaudio.load(input_file)\n",
    "        \n",
    "        # Resample the WAV file to meet the requirements of DeepFilterNet\n",
    "        resampler = torchaudio.transforms.Resample(orig_freq=sr, new_freq=new_sample_rate)\n",
    "        resampled_audio = resampler(audio)\n",
    "\n",
    "        enhanced = enhance(model, df_state, resampled_audio)\n",
    "\n",
    "        # Save the enhanced audio\n",
    "        save_audio(output_file, enhanced, df_state.sr())\n",
    "\n",
    "# 初始化 TTS\n",
    "model = TTS(language=lang, tts_device=tts_device, bert_device=bert_device, use_int8=use_int8)\n",
    "\n",
    "# 取得語者資訊\n",
    "speaker_ids = model.hps.data.spk2id\n",
    "speakers = list(speaker_ids.keys())\n",
    "\n",
    "# 若指定使用 OpenVINO, 檢查該語系是否已處理過，若無則進行轉換，結果會存在 \\tts_ov_語系 路徑下 \n",
    "if use_ov:\n",
    "    ov_path = f\"tts_ov_{lang}\"\n",
    "    \n",
    "    if not Path(ov_path).exists():\n",
    "        # 將原始模型轉換成 OpenVINO IR (bin+xml) 格式\n",
    "        model.tts_convert_to_ov(ov_path, language= lang) \n",
    "\n",
    "    # 進行模型初始化\n",
    "    model.ov_model_init(ov_path, language = lang) \n",
    "\n",
    "if not use_ov: # 若未使用 OpenVINO\n",
    "     for speaker in speakers:\n",
    "        output_path = 'en_pth_{}.wav'.format(str(speaker))\n",
    "        start = time.perf_counter()\n",
    "        model.tts_to_file(text, speaker_ids[speaker], output_path, speed=speed*0.75, use_ov = use_ov)\n",
    "        end = time.perf_counter()\n",
    "else: # 若使用 OpenVINO\n",
    "    for speaker in speakers:\n",
    "        output_path = 'ov_en_int8_{}.wav'.format(speaker) if use_int8 else 'en_ov_{}.wav'.format(speaker)\n",
    "        start = time.perf_counter()\n",
    "        model.tts_to_file(text, speaker_ids[speaker], output_path, speed=speed, use_ov=use_ov)\n",
    "        \n",
    "        if speech_enhance:\n",
    "            print(\"Use speech enhance\")\n",
    "            process_audio(output_path,output_path)\n",
    "            \n",
    "        end = time.perf_counter()         \n",
    "\n",
    "dur_time = (end - start) * 1000\n",
    "print(f\"MeloTTS 文字轉語音共花費: {dur_time:.2f} ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809480fb-93b3-4ba0-b68c-6b106cd232f6",
   "metadata": {},
   "source": [
    "## 使用 Gradio 產生互動界面\n",
    "\n",
    "除在欄位上顯示操作界面外，亦可在 http://127.0.0.1:7860 (http://localhost:7860) 以網頁方式呈現。  \n",
    "\n",
    "在操作時，可自行輸入文字，選擇是否使用 OpenVINO，調整語速(50%~200%)，按下=「Submit」後就會開始轉換產生語音檔及顯示轉換耗時。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f4a8076-2fc1-4a81-a18d-0728064ffc8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861\n",
      "IMPORTANT: You are using gradio version 4.26.0, however version 4.44.1 is available, please upgrade.\n",
      "--------\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "# 定義文字轉語音處理函式 tts()\n",
    "# 輸入： content（字串）、 use_ov（布林值）、 speed（數值）\n",
    "# 輸出： \"MeloTTS 文字轉語音共花費: xx.xx ms\"（字串）、 語音檔案名稱（字串）\n",
    "def tts(content, use_ov, speed):\n",
    "    start = time.perf_counter()    \n",
    "    model.tts_to_file(content, speaker_ids[speaker], output_path, speed=speed/100, use_ov=use_ov)\n",
    "    \n",
    "    if speech_enhance:\n",
    "            print(\"Use speech enhance\")\n",
    "            process_audio(output_path,output_path)\n",
    "        \n",
    "    end = time.perf_counter()  \n",
    "    dur_time = (end - start) * 1000\n",
    "    audio = \"ov_en_int8_ZH.wav\"\n",
    "    result = f\"MeloTTS 文字轉語音共花費: {dur_time:.2f} ms\"\n",
    "    return result, audio\n",
    "\n",
    "# 建立輸人及輸出簡單應用界面\n",
    "# fn: 界面函數名稱\n",
    "# inputs: 輸人格式， 名字（標籤：名字）、是早上（複選盒）、華氏溫度（標籤：華氏（℉），滑桿，最小值0，最大值100，預設值50）\n",
    "# outputs: 輸出格式，結果字串（標籤:輸出）、結果溫度（標籤：攝氏（℃））\n",
    "demo = gr.Interface(\n",
    "    fn=tts,\n",
    "    inputs=[gr.Textbox(label=\"文字\", value = \"請輸入文字內容\"),\n",
    "            gr.Checkbox(value=True, label=\"Use_OpenCV\"),\n",
    "            gr.Slider(50, 200, value=100, label=\"語速(%)\") ],\n",
    "    outputs=[gr.Textbox(label=\"轉換時間\"),\n",
    "             gr.Audio(label=\"輸出結果\", type=\"filepath\")],\n",
    ")\n",
    "\n",
    "# 執行顯示界面\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f139963-d4b5-45b9-9a8d-93090870f84f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
