{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "778c65ab-777d-4fe4-92c8-dc41f152863d",
   "metadata": {},
   "source": [
    "# wav2lip 單獨運行含Gradio界面範例 (wav2lip_run.ipynb)\n",
    "\n",
    "by Jack OmniXRI, 2024/12/12\n",
    "\n",
    "本範例為簡化版，運行前必需執行過 wav2lip.ipynb，下載及轉換好相關檔案，包括:  \n",
    "*  notebook_utils.py, pip_helper.py, cmd_helper.py\n",
    "*  gradio_helper.py, ov_inference.py, ov_wav2lip_helper.py\n",
    "*  data_audio_sun_5s.wav, data_vidio_sun_5s.mp4 \n",
    "*  \\wav2lip 下所有模組\n",
    "*  \\models\\face_detection.bin & xml,  \\models\\wav2lip.bin & xml\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4257000c-83da-4ab2-81ef-0931992207b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d9458bbb7df456aa45548193409049f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Device:', index=3, options=('CPU', 'GPU', 'NPU', 'AUTO'), value='AUTO')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from notebook_utils import device_widget\n",
    "\n",
    "# 設定下拉式選單，以選擇推論裝置 (CPU, GPU, NPU, AUTO) (這裡的GPU是指Intel內顯）\n",
    "device = device_widget() \n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d74fdaf7-79df-4d04-be8b-9f38697af2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "#print(os.path.abspath('.'))\n",
    "sys.path.append('./wav2lip') # 為了讓系統找得到 wav2lip 相關函式，所以手動加入相關路徑\n",
    "\n",
    "OV_FACE_DETECTION_MODEL_PATH = Path(\"models/face_detection.xml\") # 指定人臉偵測模型路徑\n",
    "OV_WAV2LIP_MODEL_PATH = Path(\"models/wav2lip.xml\") # 指定 wav2lip 模型路徑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6032dd4f-8d80-4a63-aa01-466fb96c1e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading video frames...\n",
      "Number of frames available for inference: 125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\omnixri\\openvino_notebooks\\2024_4\\openvino_notebooks\\notebooks\\digital_human\\Wav2Lip\\audio.py:100: FutureWarning: Pass sr=16000, n_fft=800 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  return librosa.filters.mel(hp.sample_rate, hp.n_fft, n_mels=hp.num_mels,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80, 405)\n",
      "Length of mel chunks: 123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                    | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "face_detect_ov images[0].shape:  (768, 576, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                    | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█████████▌                                                                  | 1/8 [00:19<02:15, 19.41s/it]\u001b[A\n",
      " 25%|███████████████████                                                         | 2/8 [00:38<01:54, 19.16s/it]\u001b[A\n",
      " 38%|████████████████████████████▌                                               | 3/8 [00:57<01:36, 19.20s/it]\u001b[A\n",
      " 50%|██████████████████████████████████████                                      | 4/8 [01:16<01:16, 19.19s/it]\u001b[A\n",
      " 62%|███████████████████████████████████████████████▌                            | 5/8 [01:35<00:57, 19.17s/it]\u001b[A\n",
      " 75%|█████████████████████████████████████████████████████████                   | 6/8 [01:55<00:38, 19.17s/it]\u001b[A\n",
      " 88%|██████████████████████████████████████████████████████████████████▌         | 7/8 [02:14<00:19, 19.13s/it]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 8/8 [02:27<00:00, 18.44s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 1/1 [02:31<00:00, 151.29s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'results/result_voice.mp4'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ov_inference import ov_inference\n",
    "\n",
    "# 確認存放輸出結果路徑是否存在，若否則建立 \\results 路徑\n",
    "if not os.path.exists(\"results\"):\n",
    "    os.mkdir(\"results\")\n",
    "\n",
    "# 使用 OpenVINO 進行推論\n",
    "ov_inference(\n",
    "    \"data_video_sun_5s.mp4\", # 指定原始影片檔案\n",
    "    \"data_audio_sun_5s.wav\", # 指定聲音檔案\n",
    "    face_detection_path=OV_FACE_DETECTION_MODEL_PATH, # 指定人臉偵測模型路徑\n",
    "    wav2lip_path=OV_WAV2LIP_MODEL_PATH, # 指定 wav2lip 模型路徑\n",
    "    inference_device=device.value, # 指定推論裝置\n",
    "    outfile=\"results/result_voice.mp4\", # 輸出結果檔案名稱\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a4fefe",
   "metadata": {},
   "source": [
    "## 使用 Gradio 產生互動界面\n",
    "\n",
    "除在欄位上顯示操作界面外，亦可在 http://127.0.0.1:7860 (http://localhost:7860) 以網頁方式呈現。  \n",
    "在操作時，最下方有預設樣本(Examples)，點擊後會自動載入輸入端，當按下「Submit」後，即會開始轉換影片。  \n",
    "這裡亦可自行選擇檔案上傳影音檔案或以網路攝影機拍攝及錄音，再進行轉換。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063d1573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORTANT: You are using gradio version 4.26.0, however version 4.44.1 is available, please upgrade.\n",
      "--------\n",
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from gradio_helper import make_demo\n",
    "\n",
    "demo = make_demo(fn=ov_inference)\n",
    "\n",
    "try:\n",
    "    demo.queue().launch(debug=True)\n",
    "except Exception:\n",
    "    demo.queue().launch(debug=True, share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da0d01c-ff16-48af-bca3-379397c5c509",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "openvino_notebooks": {
   "imageUrl": "https://github.com/user-attachments/assets/11d2fb00-4b5a-45f3-b13b-49636b0d48b1",
   "tags": {
    "categories": [
     "Model Demos",
     "AI Trends"
    ],
    "libraries": [],
    "other": [],
    "tasks": [
     "Audio-to-Video",
     "Lip-Sync"
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
